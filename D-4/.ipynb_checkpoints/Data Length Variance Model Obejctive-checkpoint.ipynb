{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516aaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(PATH_INTERMEDIATE, 'calorie_count_binary_personal-15min.pkl')\n",
    "X, y, groups, t, datetimes = load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef56240",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b51199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the features into different categories\n",
    "feat_current = X.loc[:,[('#VAL' in str(x)) or ('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_dsc = X.loc[:,[('#DSC' in str(x))  for x in X.keys()]]  \n",
    "feat_yesterday = X.loc[:,[('Yesterday' in str(x))  for x in X.keys()]]  \n",
    "feat_today = X.loc[:,[('Today' in str(x))  for x in X.keys()]]  \n",
    "feat_sleep = X.loc[:,[('Sleep' in str(x))  for x in X.keys()]]  \n",
    "feat_time = X.loc[:,[('Time' in str(x))  for x in X.keys()]]  \n",
    "feat_pif = X.loc[:,[('PIF' in str(x))  for x in X.keys()]]  \n",
    "feat_ImmediatePast = X.loc[:,[('ImmediatePast_15' in str(x))  for x in X.keys()]]\n",
    "#Divide the time window features into sensor/past stress label\n",
    "feat_current_sensor = X.loc[:,[('#VAL' in str(x))  for x in X.keys()]]  \n",
    "feat_current_ESM = X.loc[:,[('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_ImmediatePast_sensor = feat_ImmediatePast.loc[:,[('ESM' not in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_ImmediatePast_ESM = feat_ImmediatePast.loc[:,[('ESM'  in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_today_sensor = feat_today.loc[:,[('ESM' not in str(x))  for x in feat_today.keys()]]  \n",
    "feat_today_ESM = feat_today.loc[:,[('ESM'  in str(x)) for x in feat_today.keys()]]  \n",
    "feat_yesterday_sensor = feat_yesterday.loc[:,[('ESM' not in str(x)) for x in feat_yesterday.keys()]]  \n",
    "feat_yesterday_ESM = feat_yesterday.loc[:,[('ESM'  in str(x)) for x in feat_yesterday.keys()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ea598",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_baseline = pd.concat([ feat_time,feat_dsc,feat_current_sensor, feat_ImmediatePast_sensor],axis=1)\n",
    "feat_final = pd.concat([feat_baseline  ], axis=1)\n",
    "# # Fill NaN values with zeros\n",
    "feat_final = feat_final.fillna(0)\n",
    "X = feat_final\n",
    "cats = X.columns[X.dtypes == bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = X.columns.tolist()\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_parts = set()\n",
    "for col in cn:\n",
    "    part = col.split('#')[0]  # Get the part before the first '#'\n",
    "    unique_parts.add(part)\n",
    "\n",
    "# Print the unique parts\n",
    "print(unique_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8863d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8fb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3613c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from datetime import timedelta\n",
    "\n",
    "# Convert datetimes to pandas datetime format if they aren't already\n",
    "datetimes = pd.to_datetime(datetimes)\n",
    "\n",
    "# Find the unique weeks in your data\n",
    "week_starts = datetimes.to_period('W').unique()\n",
    "\n",
    "# Sort weeks to ensure they're in chronological order\n",
    "week_starts = sorted(week_starts)\n",
    "\n",
    "for user in np.unique(groups):\n",
    "    user_mask = groups == user\n",
    "    user_weeks = datetimes[user_mask].to_period('W').unique()\n",
    "    print(f\"User {user} has {len(user_weeks)} unique weeks of data.\")\n",
    "\n",
    "# Use the last week as the test set\n",
    "# Create an empty list to store indices for the test set\n",
    "test_indices = []\n",
    "\n",
    "for user in np.unique(groups):\n",
    "    user_mask = groups == user\n",
    "    user_datetimes = datetimes[user_mask]\n",
    "    user_weeks = user_datetimes.to_period('W').unique()\n",
    "    \n",
    "    # Determine the number of test weeks based on the number of available weeks for the user\n",
    "    if len(user_weeks) == 7:\n",
    "        user_last_weeks = user_weeks[-3:]  # Last 3 weeks for users with 7 weeks of data\n",
    "    elif len(user_weeks) == 6:\n",
    "        user_last_weeks = user_weeks[-2:]  # Last 2 weeks for users with 6 weeks of data\n",
    "    elif len(user_weeks) == 5:\n",
    "        user_last_weeks = user_weeks[-1:]  # Last week for users with 5 weeks of data\n",
    "    else:\n",
    "        continue  # Skip users with fewer than 5 weeks of data (if applicable)\n",
    "    \n",
    "    # Create a mask for the test set based on the identified weeks\n",
    "    user_test_mask = (datetimes.to_period('W').isin(user_last_weeks)) & user_mask\n",
    "    test_indices.extend(np.where(user_test_mask)[0])\n",
    "    \n",
    "# Create the final test set\n",
    "X_test = X.iloc[test_indices]\n",
    "y_test = y[test_indices]\n",
    "groups_test = groups[test_indices]\n",
    "\n",
    "# Remove the test data from the training data\n",
    "train_mask = ~X.index.isin(test_indices)\n",
    "X_train_full = X[train_mask]\n",
    "y_train_full = y[train_mask]\n",
    "groups_train_full = groups[train_mask]\n",
    "datetimes_train_full = datetimes[train_mask]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Determine the maximum number of weeks that can be used for training, excluding the test set weeks\n",
    "max_weeks = len(week_starts) - 3\n",
    "print(\"max weeks\")\n",
    "print(max_weeks)\n",
    "# Loop over the weeks, incrementally adding more data to the training set\n",
    "for i in range(1, max_weeks):\n",
    "    # Use the first `i` weeks for the training set\n",
    "    train_weeks = week_starts[:i]\n",
    "    incremental_train_mask = datetimes_train_full.to_period('W').isin(train_weeks)\n",
    "\n",
    "    # Ensure consistent duration for all users in training\n",
    "    X_train = X_train_full[incremental_train_mask]\n",
    "    y_train = y_train_full[incremental_train_mask]\n",
    "    groups_train = groups_train_full[incremental_train_mask]\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities on the test set\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Check if both classes are present in y_test\n",
    "    if len(np.unique(y_test)) > 1:\n",
    "        # Calculate AUC and store results\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        results.append({\n",
    "            'weeks_of_training': i,\n",
    "            'auc': auc\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Skipping AUC calculation for iteration {i} because only one class is present in y_test.\")\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "from IPython.display import display\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_auc_results(results_df):\n",
    "    \"\"\"\n",
    "    Plots the AUC scores against the number of weeks of training data.\n",
    "\n",
    "    Parameters:\n",
    "    - results_df: DataFrame containing 'weeks_of_training' and 'auc' columns.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot AUC Scores\n",
    "    plt.plot(results_df['weeks_of_training'], results_df['auc'], marker='o', label='Test AUC', color='green')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel('Weeks of Training Data')\n",
    "    plt.ylabel('AUC Score')\n",
    "    plt.title('Model Performance with Increasing Training Data')\n",
    "    plt.legend()\n",
    "\n",
    "    # Grid and show plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Use the plot function after generating the results\n",
    "plot_auc_results(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f015371",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_auc_and_ci_from_predictions(bootstrap_predictions, y_true, ci=95):\n",
    "    \"\"\"\n",
    "    Calculate AUC and confidence interval directly from bootstrap predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - bootstrap_predictions: List of predicted probabilities from bootstrapped test sets\n",
    "    - y_true: Original true labels for each resampled test set\n",
    "    - ci: Confidence interval percentage\n",
    "    \n",
    "    Returns:\n",
    "    - mean_auc: Mean AUC score across bootstrap samples\n",
    "    - lower_ci: Lower bound of the confidence interval\n",
    "    - upper_ci: Upper bound of the confidence interval\n",
    "    \"\"\"\n",
    "    aucs = []\n",
    "    for i in range(len(bootstrap_predictions)):\n",
    "        auc = roc_auc_score(y_true[i], bootstrap_predictions[i])\n",
    "        aucs.append(auc)\n",
    "    \n",
    "    mean_auc = np.mean(aucs)\n",
    "    lower_ci = np.percentile(aucs, (100 - ci) / 2)\n",
    "    upper_ci = np.percentile(aucs, 100 - (100 - ci) / 2)\n",
    "    \n",
    "    return mean_auc, lower_ci, upper_ci\n",
    "\n",
    "def bootstrap_resample_test_set(X_test, y_test, n_bootstraps=1000, test_size=0.5):\n",
    "    resampled_X_tests = []\n",
    "    resampled_y_tests = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        X_resampled, y_resampled = resample(X_test, y_test, replace=True, n_samples=int(len(X_test) * test_size))\n",
    "        resampled_X_tests.append(X_resampled)\n",
    "        resampled_y_tests.append(y_resampled)\n",
    "    \n",
    "    return resampled_X_tests, resampled_y_tests\n",
    "\n",
    "def train_and_predict_bootstrap(X_train, y_train, resampled_X_tests, resampled_y_tests, n_estimators=100):\n",
    "    model = xgb.XGBClassifier(n_estimators=n_estimators, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    bootstrap_predictions = []\n",
    "    for X_resampled in resampled_X_tests:\n",
    "        preds = model.predict_proba(X_resampled)[:, 1]\n",
    "        bootstrap_predictions.append(preds)\n",
    "    \n",
    "    return bootstrap_predictions\n",
    "\n",
    "def plot_confidence_intervals(X_test, y_test, bootstrap_predictions, lower_bounds, upper_bounds):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_predictions = np.mean(bootstrap_predictions, axis=0)\n",
    "    plt.plot(mean_predictions, 'o', label='Mean Prediction')\n",
    "    plt.fill_between(range(len(mean_predictions)), lower_bounds, upper_bounds, color='gray', alpha=0.2, label=f'95% Confidence Interval')\n",
    "    plt.plot(y_test, 'x', label='True Labels', color='red')\n",
    "    plt.xlabel('Test Data Point Index')\n",
    "    plt.ylabel('Predicted Probability')\n",
    "    plt.title('Confidence Intervals of Predictions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1, max_weeks):\n",
    "    train_weeks = week_starts[:i]\n",
    "    incremental_train_mask = datetimes_train_full.to_period('W').isin(train_weeks)\n",
    "\n",
    "    X_train = X_train_full[incremental_train_mask]\n",
    "    y_train = y_train_full[incremental_train_mask]\n",
    "    groups_train = groups_train_full[incremental_train_mask]\n",
    "\n",
    "    resampled_X_tests, resampled_y_tests = bootstrap_resample_test_set(X_test, y_test, n_bootstraps=1000)\n",
    "    bootstrap_predictions = train_and_predict_bootstrap(X_train, y_train, resampled_X_tests, resampled_y_tests)\n",
    "    \n",
    "    mean_auc, lower_ci, upper_ci = calculate_auc_and_ci_from_predictions(bootstrap_predictions, resampled_y_tests)\n",
    "\n",
    "    results.append({\n",
    "        'weeks_of_training': i,\n",
    "        'mean_auc': mean_auc,\n",
    "        'lower_ci': lower_ci,\n",
    "        'upper_ci': upper_ci\n",
    "    })\n",
    "\n",
    "    plot_confidence_intervals(X_test, y_test, bootstrap_predictions, lower_ci, upper_ci)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n",
    "\n",
    "def plot_auc_with_confidence_intervals(results_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(results_df['weeks_of_training'], results_df['mean_auc'], \n",
    "                 yerr=[results_df['mean_auc'] - results_df['lower_ci'], results_df['upper_ci'] - results_df['mean_auc']],\n",
    "                 fmt='o', ecolor='red', capsize=5, label='Test AUC with 95% CI', color='green')\n",
    "    plt.xlabel('Weeks of Training Data')\n",
    "    plt.ylabel('AUC Score')\n",
    "    plt.title('Model Performance and Confidence Interval with Increasing Training Data')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_auc_with_confidence_intervals(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe95207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract relevant data from results_df\n",
    "weeks_of_training = results_df['weeks_of_training']\n",
    "mean_auc = results_df['mean_auc']\n",
    "lower_ci = results_df['lower_ci']\n",
    "upper_ci = results_df['upper_ci']\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the mean AUC over time\n",
    "plt.plot(weeks_of_training, mean_auc, label='Mean AUC', color='blue')\n",
    "\n",
    "# Fill the area between the lower and upper confidence intervals\n",
    "plt.fill_between(weeks_of_training, lower_ci, upper_ci, color='gray', alpha=0.5, label='95% Confidence Interval')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('AUC and Confidence Interval Over Increasing Training Data')\n",
    "plt.xlabel('Weeks of Training Data')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2befd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
